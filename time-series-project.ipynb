{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c77ce0",
   "metadata": {},
   "source": [
    "# COMP47670 Assignment II Autumn 2023\n",
    "## Time Series Running Data\n",
    "\n",
    "## Objective\n",
    "The objective of this assignment is to identify good models for classifying time series data.  \n",
    "The data is from an accelerometer sensor and there are samples of fatigued and non-fatigued running. The data has been segmented into strides and the segments (samples) are labelled F (fatigued) and NF (not fatigued). The data for two subjects A and B are available in the files  `fatigueA.csv` and  `fatigueB.csv`. This dataset is extracted from a much larger dataset described [here](https://openreview.net/pdf?id=9c0lAonDNP).  \n",
    "At present, the best performing method for time-series classification is [Rocket](https://openreview.net/pdf?id=9c0lAonDNP). \n",
    "A rocket implementation is available in the [sktime tool kit](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.transformations.panel.rocket.Rocket.html). This sktime implementation can be used in this assignment.   \n",
    "Some code to get you started in available in the notebook `RunningCore`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed655030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fddb22e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421, 181)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.89</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.82</td>\n",
       "      <td>...</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.29</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.29</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.09</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.79</td>\n",
       "      <td>3.88</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.88</td>\n",
       "      <td>6.80</td>\n",
       "      <td>6.13</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.69</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.52</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.91</td>\n",
       "      <td>...</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.29</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>2.42</td>\n",
       "      <td>3.21</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.42</td>\n",
       "      <td>...</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.32</td>\n",
       "      <td>7.34</td>\n",
       "      <td>5.91</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.89</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.66</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.25</td>\n",
       "      <td>...</td>\n",
       "      <td>9.45</td>\n",
       "      <td>8.52</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.14</td>\n",
       "      <td>6.63</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0     1     2     3     4     5     6     7     8     9    ...   171   172  \\\n",
       "0   F  2.72  2.69  2.75  2.89  3.07  3.27  3.48  3.67  3.82  ...  6.50  6.16   \n",
       "1   F  2.68  2.47  2.46  2.54  2.69  2.93  3.36  3.99  4.75  ...  2.79  3.88   \n",
       "2   F  5.04  5.69  6.21  6.52  6.59  6.47  6.26  6.06  5.91  ...  5.89  5.29   \n",
       "3   F  2.42  3.21  4.02  4.58  4.77  4.64  4.39  4.25  4.42  ...  8.60  8.76   \n",
       "4   F  3.35  3.40  3.89  4.71  5.66  6.47  6.90  6.81  6.25  ...  9.45  8.52   \n",
       "\n",
       "    173   174   175   176   177   178   179   180  \n",
       "0  5.75  5.29  4.79  4.29  3.83  3.42  3.09  2.85  \n",
       "1  5.18  6.29  6.88  6.80  6.13  5.11  4.04  3.20  \n",
       "2  4.72  4.20  3.77  3.47  3.36  3.47  3.82  4.38  \n",
       "3  8.76  8.32  7.34  5.91  4.33  2.97  2.14  1.98  \n",
       "4  7.75  7.14  6.63  6.15  5.60  4.96  4.28  3.69  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fatigue_df = pd.read_csv('fatigueA.csv', header = None) # sep = '\\s+')\n",
    "print(fatigue_df.shape)\n",
    "fatigue_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936131c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accel Mag')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fatigue_df.iloc[4][1:].plot(label='Fatigued')\n",
    "fatigue_df.iloc[-5][1:].plot(figsize=(4,3), label = 'Not Fatigued')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15),ncol=2)\n",
    "plt.ylabel('Accel Mag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2141ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fatigue_df.pop(0).values\n",
    "X = fatigue_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559bdcd9",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Calculate the accuracy of a logistic regression classifier (`SGDClassifier`) on the raw time series data for subject A. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d0d8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((421, 180), (421,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc22ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression classifier on fatigue A: 0.69\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = SGDClassifier(loss='log_loss', random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of the Logistic Regression classifier on fatigue A: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53115f94",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "The RunningCore Notebook contains code to convert the data to the `sktime` time-series format. Using this format assess the accuracy of the Rocket transformer coupled with an `SGDClassifier` classifier on the data for subject A. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff530507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 1, 180)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3d = X[:,np.newaxis,:] # time series algs require a 3D data array (sample, var, tick)\n",
    "X3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af39f3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9529411764705882\n"
     ]
    }
   ],
   "source": [
    "X_train_x3d, X_test_x3d, y_train, y_test = train_test_split(X3d, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(X_train_x3d)\n",
    "X_train_transform = rocket.transform(X_train_x3d)\n",
    "X_test_transform = rocket.transform(X_test_x3d)\n",
    "\n",
    "classifier.fit(X_train_transform, y_train)\n",
    "#accuracy = classifier.score(X_test_transform, y_test)\n",
    "\n",
    "y_pred = classifier.predict(X_test_transform)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Use StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SGDClassifier: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "classifier = SGDClassifier(loss='log_loss', random_state=42)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with SGDClassifier: {accuracy_sgd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'eta0': 0.2, 'learning_rate': 'adaptive', 'penalty': 'elasticnet'}\n",
      "Accuracy with SGDClassifier: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'eta0': [0.01, 0.1, 0.2],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet']\n",
    "}\n",
    "\n",
    "sgd_classifier = SGDClassifier(loss='log_loss', random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(sgd_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_classifier.predict(X_test_scaled)\n",
    "accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy with SGDClassifier: {accuracy_sgd}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging Classifier: 0.8941176470588236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "ensemble_classifier = BaggingClassifier(classifier, n_estimators=10, random_state=42)\n",
    "ensemble_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(X_test_scaled)\n",
    "accuracy_bag = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Bagging Classifier: {accuracy_bag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ramdom Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with Random Forest: {accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest: 0.9529411764705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with Random Forest: {accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7556 - accuracy: 0.5833\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7619\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8810\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.9256\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9464\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9494\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Accuracy with Neural Network: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Neural Network: {accuracy_nn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Support Vector Machine: 0.9647058823529412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel='rbf', random_state=42)  \n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Support Vector Machine: {accuracy_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. k-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k-Nearest Neighbors: 0.9294117647058824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with k-Nearest Neighbors: {accuracy_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Results:\n",
      "SGDClassifier: 0.8824\n",
      "BaggingClassifier: 0.8941\n",
      "Neural Network: 0.9412\n",
      "SVM: 0.9647\n",
      "Random Forest: 0.9529\n",
      "k-Nearest Neighbors: 0.9294\n",
      "\n",
      "Best Model: SVM with Accuracy: 0.9647\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"SGDClassifier\": accuracy_sgd,\n",
    "    \"BaggingClassifier\": accuracy_bag,\n",
    "    \"Neural Network\": accuracy_nn,\n",
    "    \"SVM\": accuracy_svm,\n",
    "    \"Random Forest\": accuracy_rf,\n",
    "    \"k-Nearest Neighbors\": accuracy_knn,\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(\"\\nCombined Results:\")\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n",
    "print(f\"\\nBest Model: {best_model} with Accuracy: {results[best_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The SVM (Support Vector Machine) model achieved the highest accuracy (96.47%) among the classifiers tested, making it the best-performing model. Other models, such as the Neural Network, Random Forest, Gradient Boosting, SGDClassifier, BaggingClassifier and k-Nearest Neighbors, also demonstrated good performance, but SVM stood out as the most accurate classifier for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Test the Rocket transformer with different numbers of kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x3d, X_test_x3d, y_train, y_test = train_test_split(X3d, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(X_train_x3d)\n",
    "X_train_transform = rocket.transform(X_train_x3d)\n",
    "X_test_transform = rocket.transform(X_test_x3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SGDClassifier: 0.788235294117647\n"
     ]
    }
   ],
   "source": [
    "classifier = SGDClassifier(loss='log_loss', random_state=42)\n",
    "classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_transform)\n",
    "accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with SGDClassifier: {accuracy_sgd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging Classifier: 0.9529411764705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "ensemble_classifier = BaggingClassifier(classifier, n_estimators=10, random_state=42)\n",
    "ensemble_classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(X_test_transform)\n",
    "accuracy_bag = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Bagging Classifier: {accuracy_bag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ramdom Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest: 0.9529411764705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_transform)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with Random Forest: {accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 9ms/step - loss: 19.2674 - accuracy: 0.4673\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 9.0953 - accuracy: 0.5327\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.1354 - accuracy: 0.6310\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8513 - accuracy: 0.7917\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5577 - accuracy: 0.8423\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4474 - accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.7890 - accuracy: 0.7589\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.8274\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3255 - accuracy: 0.8929\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Accuracy with Neural Network: 0.9058823529411765\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_transform.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_transform, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "y_pred_proba = model.predict(X_test_transform)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Neural Network: {accuracy_nn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Support Vector Machine: 0.8941176470588236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel='rbf', random_state=42)  \n",
    "classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_transform)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Support Vector Machine: {accuracy_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Gradient Boosting: 0.9529411764705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred_gb = gb_classifier.predict(X_test_transform)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Accuracy with Gradient Boosting: {accuracy_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Results:\n",
      "SGDClassifier: 0.7882\n",
      "Neural Network: 0.9059\n",
      "SVM: 0.8941\n",
      "Random Forest: 0.9529\n",
      "Gradient Boosting: 0.9529\n",
      "\n",
      "Best Model: Random Forest with Accuracy: 0.9529\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"SGDClassifier\": accuracy_sgd,\n",
    "    \"Neural Network\": accuracy_nn,\n",
    "    \"SVM\": accuracy_svm,\n",
    "    \"Random Forest\": accuracy_rf,\n",
    "    \"Gradient Boosting\": accuracy_gb,\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(\"\\nCombined Results:\")\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n",
    "print(f\"\\nBest Model: {best_model} with Accuracy: {results[best_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier Accuracies: [0.8117647058823529, 0.7647058823529411, 0.6705882352941176, 0.8941176470588236, 0.6470588235294118, 0.8470588235294118]\n",
      "Neural Network Accuracies: [0.8235294117647058, 0.8705882352941177, 0.8941176470588236, 0.9647058823529412, 0.8941176470588236, 0.9529411764705882]\n",
      "SVM Accuracies: [0.8235294117647058, 0.7529411764705882, 0.8470588235294118, 0.8941176470588236, 0.8705882352941177, 0.8941176470588236]\n",
      "Random Forest Accuracies: [0.9176470588235294, 0.9058823529411765, 0.9176470588235294, 0.9529411764705882, 0.9529411764705882, 0.9411764705882353]\n"
     ]
    }
   ],
   "source": [
    "X_train_x3d, X_test_x3d, y_train, y_test = train_test_split(X3d, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_kernels_list = [10,30,50,70,90,110]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for num_kernels in num_kernels_list:\n",
    "    rocket = Rocket(num_kernels=num_kernels)\n",
    "    rocket.fit(X_train_x3d)\n",
    "    \n",
    "    X_train_transform = rocket.transform(X_train_x3d)\n",
    "    X_test_transform = rocket.transform(X_test_x3d)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SGDClassifier\": SGDClassifier(random_state=42),\n",
    "        \"Neural Network\": MLPClassifier(random_state=42),\n",
    "        \"SVM\": SVC(kernel='rbf', random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    }\n",
    "\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        classifier.fit(X_train_transform, y_train)\n",
    "        y_pred = classifier.predict(X_test_transform)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.setdefault(classifier_name, []).append(accuracy)\n",
    "\n",
    "for classifier_name, accuracies in results.items():\n",
    "    print(f\"{classifier_name} Accuracies: {accuracies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier - Best Accuracy: 0.8941 with num_kernels=70\n",
      "Neural Network - Best Accuracy: 0.9647 with num_kernels=70\n",
      "SVM - Best Accuracy: 0.8941 with num_kernels=70\n",
      "Random Forest - Best Accuracy: 0.9529 with num_kernels=70\n"
     ]
    }
   ],
   "source": [
    "best_accuracies = {}\n",
    "best_num_kernels = {}\n",
    "\n",
    "for classifier_name, accuracies in results.items():\n",
    "    best_accuracy = max(accuracies)\n",
    "    best_index = accuracies.index(best_accuracy)\n",
    "    best_num_kernel = num_kernels_list[best_index]\n",
    "\n",
    "    best_accuracies[classifier_name] = best_accuracy\n",
    "    best_num_kernels[classifier_name] = best_num_kernel\n",
    "\n",
    "for classifier_name, best_accuracy in best_accuracies.items():\n",
    "    best_kernel = best_num_kernels[classifier_name]\n",
    "    print(f\"{classifier_name} - Best Accuracy: {best_accuracy:.4f} with num_kernels={best_kernel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the optimal number of kernels across different classifiers consistently appears to be 70. The Neural Network achieved the highest accuracy among all classifiers at 0.9647, closely followed by the Random Forest classifier, which consistently performed well with accuracies above 0.9. The performance of the SGDClassifier and SVM varied more across runs, and their optimal number of kernels was also found to be 70."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>1.49</td>\n",
       "      <td>4.09</td>\n",
       "      <td>9.27</td>\n",
       "      <td>12.70</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.40</td>\n",
       "      <td>13.20</td>\n",
       "      <td>13.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.30</td>\n",
       "      <td>9.61</td>\n",
       "      <td>9.25</td>\n",
       "      <td>8.07</td>\n",
       "      <td>7.62</td>\n",
       "      <td>8.76</td>\n",
       "      <td>9.61</td>\n",
       "      <td>7.63</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.94</td>\n",
       "      <td>7.34</td>\n",
       "      <td>6.48</td>\n",
       "      <td>5.87</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.20</td>\n",
       "      <td>...</td>\n",
       "      <td>8.92</td>\n",
       "      <td>7.66</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8.28</td>\n",
       "      <td>8.99</td>\n",
       "      <td>10.20</td>\n",
       "      <td>11.60</td>\n",
       "      <td>11.90</td>\n",
       "      <td>10.70</td>\n",
       "      <td>8.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>9.31</td>\n",
       "      <td>9.06</td>\n",
       "      <td>9.41</td>\n",
       "      <td>9.51</td>\n",
       "      <td>9.23</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.08</td>\n",
       "      <td>8.45</td>\n",
       "      <td>7.63</td>\n",
       "      <td>...</td>\n",
       "      <td>11.40</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.75</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>9.82</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.86</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.60</td>\n",
       "      <td>9.97</td>\n",
       "      <td>9.50</td>\n",
       "      <td>8.15</td>\n",
       "      <td>...</td>\n",
       "      <td>11.50</td>\n",
       "      <td>10.60</td>\n",
       "      <td>9.07</td>\n",
       "      <td>7.65</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.28</td>\n",
       "      <td>5.09</td>\n",
       "      <td>4.77</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>4.68</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>11.90</td>\n",
       "      <td>10.60</td>\n",
       "      <td>11.10</td>\n",
       "      <td>12.90</td>\n",
       "      <td>14.00</td>\n",
       "      <td>13.60</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>11.50</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>NF</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.91</td>\n",
       "      <td>6.08</td>\n",
       "      <td>6.72</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.15</td>\n",
       "      <td>8.23</td>\n",
       "      <td>...</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.18</td>\n",
       "      <td>9.72</td>\n",
       "      <td>9.54</td>\n",
       "      <td>8.58</td>\n",
       "      <td>7.64</td>\n",
       "      <td>6.76</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NF</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.82</td>\n",
       "      <td>7.60</td>\n",
       "      <td>8.36</td>\n",
       "      <td>9.01</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.04</td>\n",
       "      <td>8.79</td>\n",
       "      <td>...</td>\n",
       "      <td>13.70</td>\n",
       "      <td>12.90</td>\n",
       "      <td>11.80</td>\n",
       "      <td>9.63</td>\n",
       "      <td>7.22</td>\n",
       "      <td>5.84</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.63</td>\n",
       "      <td>5.09</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>NF</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.83</td>\n",
       "      <td>7.89</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.99</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.60</td>\n",
       "      <td>...</td>\n",
       "      <td>8.02</td>\n",
       "      <td>7.02</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.33</td>\n",
       "      <td>5.77</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NF</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.72</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.55</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.50</td>\n",
       "      <td>...</td>\n",
       "      <td>7.68</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.54</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.12</td>\n",
       "      <td>4.64</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>NF</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.58</td>\n",
       "      <td>...</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.65</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.43</td>\n",
       "      <td>6.83</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1      2     3      4      5      6      7      8      9    ...  \\\n",
       "0     F  1.49   4.09  9.27  12.70  12.80  12.00  12.40  13.20  13.00  ...   \n",
       "1     F  7.35   7.25  7.80   7.94   7.34   6.48   5.87   5.47   5.20  ...   \n",
       "2     F  9.31   9.06  9.41   9.51   9.23   9.14   9.08   8.45   7.63  ...   \n",
       "3     F  9.82  10.50  9.86  10.20  10.90  10.60   9.97   9.50   8.15  ...   \n",
       "4     F  4.68   3.68  4.63   5.01   4.05   3.40   4.00   4.62   4.25  ...   \n",
       "..   ..   ...    ...   ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "246  NF  5.47   5.91  6.08   6.72   8.01   8.76   8.48   8.15   8.23  ...   \n",
       "247  NF  4.79   5.81  6.82   7.60   8.36   9.01   9.19   9.04   8.79  ...   \n",
       "248  NF  4.05   4.92  5.89   6.83   7.89   8.74   8.99   8.86   8.60  ...   \n",
       "249  NF  3.98   4.71  4.72   5.26   6.18   6.55   7.01   7.75   7.50  ...   \n",
       "250  NF  2.25   2.02  2.81   2.77   2.76   2.86   2.86   3.17   3.58  ...   \n",
       "\n",
       "       171    172    173    174    175    176    177    178    179    180  \n",
       "0     9.53   9.30   9.61   9.25   8.07   7.62   8.76   9.61   7.63   3.57  \n",
       "1     8.92   7.66   7.76   8.28   8.99  10.20  11.60  11.90  10.70   8.72  \n",
       "2    11.40  10.50   9.63   9.29   9.75  10.20  10.10  10.10  10.20  10.00  \n",
       "3    11.50  10.60   9.07   7.65   6.83   6.67   6.28   5.09   4.77   7.00  \n",
       "4    11.90  10.60  11.10  12.90  14.00  13.60  13.00  12.80  11.50   8.12  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "246  11.00   9.36   9.18   9.72   9.54   8.58   7.64   6.76   5.73   5.18  \n",
       "247  13.70  12.90  11.80   9.63   7.22   5.84   5.64   5.63   5.09   4.53  \n",
       "248   8.02   7.02   6.58   6.33   5.77   4.99   4.51   4.36   4.11   3.80  \n",
       "249   7.68   7.50   6.54   5.74   5.45   5.12   4.64   3.91   2.97   2.90  \n",
       "250   4.06   4.83   4.90   4.75   5.65   5.89   5.43   6.83   8.00   5.46  \n",
       "\n",
       "[251 rows x 181 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fatigue_df2 = pd.read_csv('fatigueB.csv', header = None)\n",
    "fatigue_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fatigue_df2.pop(0).values\n",
    "X = fatigue_df2.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task5-Task3\n",
    "StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SGDClassifier: 0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "classifier = SGDClassifier(loss='log_loss', random_state=42)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with SGDClassifier: {accuracy_sgd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'eta0': 0.2, 'learning_rate': 'invscaling', 'penalty': 'elasticnet'}\n",
      "Accuracy with SGDClassifier: 0.8627450980392157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'eta0': [0.01, 0.1, 0.2],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet']\n",
    "}\n",
    "\n",
    "sgd_classifier = SGDClassifier(loss='log_loss', random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(sgd_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_classifier.predict(X_test_scaled)\n",
    "accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy with SGDClassifier: {accuracy_sgd}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging Classifier: 0.8627450980392157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "ensemble_classifier = BaggingClassifier(classifier, n_estimators=10, random_state=42)\n",
    "ensemble_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(X_test_scaled)\n",
    "accuracy_bag = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Bagging Classifier: {accuracy_bag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ramdom Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest: 0.9019607843137255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with Random Forest: {accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest: 0.9215686274509803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with Random Forest: {accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6550\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8200\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8400\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2991 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2482 - accuracy: 0.9150\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9400\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1927 - accuracy: 0.9450\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9650\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9800\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9850\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Accuracy with Neural Network: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Neural Network: {accuracy_nn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Support Vector Machine: 0.9019607843137255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel='rbf', random_state=42)  \n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Support Vector Machine: {accuracy_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. k-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 3 neighbors: 0.9019607843137255\n",
      "Accuracy with 5 neighbors: 0.803921568627451\n",
      "Accuracy with 7 neighbors: 0.803921568627451\n",
      "Accuracy with 9 neighbors: 0.7843137254901961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for n_neighbors in [3, 5, 7, 9]:\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_classifier.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy with {n_neighbors} neighbors: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k-Nearest Neighbors: 0.9019607843137255\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with k-Nearest Neighbors: {accuracy_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Results:\n",
      "SGDClassifier: 0.8627\n",
      "BaggingClassifier: 0.8627\n",
      "Neural Network: 0.8824\n",
      "SVM: 0.9020\n",
      "Random Forest: 0.9216\n",
      "k-Nearest Neighbors: 0.9020\n",
      "\n",
      "Best Model: Random Forest with Accuracy: 0.9216\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"SGDClassifier\": accuracy_sgd,\n",
    "    \"BaggingClassifier\": accuracy_bag,\n",
    "    \"Neural Network\": accuracy_nn,\n",
    "    \"SVM\": accuracy_svm,\n",
    "    \"Random Forest\": accuracy_rf,\n",
    "    \"k-Nearest Neighbors\": accuracy_knn,\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(\"\\nCombined Results:\")\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n",
    "print(f\"\\nBest Model: {best_model} with Accuracy: {results[best_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with Accuracy: 0.9216\n",
    "\n",
    "The Random Forest model emerged as the best-performing classifier, outperforming the others with the highest accuracy of 0.9216.\n",
    "In summary, the Random Forest model stands out as the most effective classifier for this dataset, providing the highest accuracy among the models evaluated. It's important to note that the choice of the best model may depend on the specific characteristics of the data and the goals of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous result with fatigueB:\n",
    "\n",
    "Combined Results:\n",
    "- SGDClassifier: 0.8824\n",
    "- BaggingClassifier: 0.8941\n",
    "- Neural Network: 0.9412\n",
    "- SVM: 0.9647\n",
    "- Random Forest: 0.9529\n",
    "- k-Nearest Neighbors: 0.9294\n",
    "\n",
    "Best Model: SVM with Accuracy: 0.9647"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task5-Task4\n",
    "Test the Rocket transformer with different numbers of kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3d = X[:,np.newaxis,:] \n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "X_train_x3d, X_test_x3d, y_train, y_test = train_test_split(X3d, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(X_train_x3d)\n",
    "X_train_transform = rocket.transform(X_train_x3d)\n",
    "X_test_transform = rocket.transform(X_test_x3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SGDClassifier: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "classifier = SGDClassifier(loss='log_loss', random_state=42)\n",
    "classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_transform)\n",
    "accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with SGDClassifier: {accuracy_sgd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging Classifier: 0.8627450980392157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "ensemble_classifier = BaggingClassifier(classifier, n_estimators=10, random_state=42)\n",
    "ensemble_classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(X_test_transform)\n",
    "accuracy_bag = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Bagging Classifier: {accuracy_bag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ramdom Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest: 0.9215686274509803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_transform)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy with Random Forest: {accuracy_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 13.6565 - accuracy: 0.5500\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6885 - accuracy: 0.4850\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Accuracy with Neural Network: 0.4117647058823529\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_transform.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_transform, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "y_pred_proba = model.predict(X_test_transform)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Neural Network: {accuracy_nn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 10ms/step - loss: 6.4481 - accuracy: 0.4700\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.2432 - accuracy: 0.5300\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.2138 - accuracy: 0.5950\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.8003 - accuracy: 0.5800\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0023 - accuracy: 0.6350\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5982 - accuracy: 0.7650\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4036 - accuracy: 0.8200\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2861 - accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2582 - accuracy: 0.9100\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2931 - accuracy: 0.8800\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Accuracy with Neural Network: 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_transform.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_transform, y_train, epochs=10, batch_size=64)\n",
    "y_pred_proba = model.predict(X_test_transform)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Neural Network: {accuracy_nn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Support Vector Machine: 0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel='rbf', random_state=42)  \n",
    "classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_transform)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Support Vector Machine: {accuracy_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy with Support Vector Machine: 0.9607843137254902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "grid_search_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train_transform, y_train)\n",
    "\n",
    "best_svm_classifier = grid_search_svm.best_estimator_\n",
    "\n",
    "y_pred_svm = best_svm_classifier.predict(X_test_transform)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"Best Accuracy with Support Vector Machine: {accuracy_svm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Gradient Boosting: 0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train_transform, y_train)\n",
    "\n",
    "y_pred_gb = gb_classifier.predict(X_test_transform)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Accuracy with Gradient Boosting: {accuracy_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Results:\n",
      "SGDClassifier: 0.8824\n",
      "Neural Network: 0.8235\n",
      "SVM: 0.9608\n",
      "Random Forest: 0.9216\n",
      "Gradient Boosting: 0.8039\n",
      "\n",
      "Best Model: SVM with Accuracy: 0.9608\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"SGDClassifier\": accuracy_sgd,\n",
    "    \"Neural Network\": accuracy_nn,\n",
    "    \"SVM\": accuracy_svm,\n",
    "    \"Random Forest\": accuracy_rf,\n",
    "    \"Gradient Boosting\": accuracy_gb,\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(\"\\nCombined Results:\")\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n",
    "print(f\"\\nBest Model: {best_model} with Accuracy: {results[best_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier Accuracies: [0.49019607843137253, 0.9411764705882353, 0.7647058823529411, 0.9215686274509803, 0.7450980392156863, 0.7450980392156863]\n",
      "Neural Network Accuracies: [0.7843137254901961, 0.9215686274509803, 0.8431372549019608, 0.8235294117647058, 0.8431372549019608, 0.8235294117647058]\n",
      "SVM Accuracies: [0.7450980392156863, 0.8823529411764706, 0.8235294117647058, 0.803921568627451, 0.7647058823529411, 0.803921568627451]\n",
      "Random Forest Accuracies: [0.8823529411764706, 0.9411764705882353, 0.8823529411764706, 0.9019607843137255, 0.8823529411764706, 0.9215686274509803]\n"
     ]
    }
   ],
   "source": [
    "X_train_x3d, X_test_x3d, y_train, y_test = train_test_split(X3d, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_kernels_list = [10,30,50,70,90,110]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for num_kernels in num_kernels_list:\n",
    "    rocket = Rocket(num_kernels=num_kernels)\n",
    "    rocket.fit(X_train_x3d)\n",
    "    \n",
    "    X_train_transform = rocket.transform(X_train_x3d)\n",
    "    X_test_transform = rocket.transform(X_test_x3d)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SGDClassifier\": SGDClassifier(random_state=42),\n",
    "        \"Neural Network\": MLPClassifier(random_state=42),\n",
    "        \"SVM\": SVC(kernel='rbf', random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    }\n",
    "\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        classifier.fit(X_train_transform, y_train)\n",
    "        y_pred = classifier.predict(X_test_transform)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.setdefault(classifier_name, []).append(accuracy)\n",
    "\n",
    "for classifier_name, accuracies in results.items():\n",
    "    print(f\"{classifier_name} Accuracies: {accuracies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier - Best Accuracy: 0.9412 with num_kernels=30\n",
      "Neural Network - Best Accuracy: 0.9216 with num_kernels=30\n",
      "SVM - Best Accuracy: 0.8824 with num_kernels=30\n",
      "Random Forest - Best Accuracy: 0.9412 with num_kernels=30\n"
     ]
    }
   ],
   "source": [
    "best_accuracies = {}\n",
    "best_num_kernels = {}\n",
    "\n",
    "for classifier_name, accuracies in results.items():\n",
    "    best_accuracy = max(accuracies)\n",
    "    best_index = accuracies.index(best_accuracy)\n",
    "    best_num_kernel = num_kernels_list[best_index]\n",
    "\n",
    "    best_accuracies[classifier_name] = best_accuracy\n",
    "    best_num_kernels[classifier_name] = best_num_kernel\n",
    "\n",
    "for classifier_name, best_accuracy in best_accuracies.items():\n",
    "    best_kernel = best_num_kernels[classifier_name]\n",
    "    print(f\"{classifier_name} - Best Accuracy: {best_accuracy:.4f} with num_kernels={best_kernel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "previous result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SGDClassifier - Best Accuracy: 0.8941 with num_kernels=70\n",
    "- Neural Network - Best Accuracy: 0.9647 with num_kernels=70\n",
    "- SVM - Best Accuracy: 0.8941 with num_kernels=70\n",
    "- Random Forest - Best Accuracy: 0.9529 with num_kernels=70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The optimal number of kernels varied between the two datasets, suggesting that the characteristics of the datasets impact the choice of this hyperparameter.\n",
    "- The Neural Network showed higher accuracy on fatigueA.csv, while the SGDClassifier performed better on fatigueB.csv.\n",
    "- SVM and Random Forest had comparable performance on both datasets, with minor variations in accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
