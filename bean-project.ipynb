{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - The Bean Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Dry_Bean_Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Class']).values\n",
    "y = df['Class'].values\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Duplicate rows:{df.duplicated().sum()}\\n')\n",
    "\n",
    "print('Bean type of duplicated rows:')\n",
    "print(df[df.duplicated()].Class.value_counts())\n",
    "\n",
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sc_X_train = StandardScaler()\n",
    "X_train = sc_X_train.fit_transform(X_train)\n",
    "X_test = sc_X_train.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "tree = DecisionTreeClassifier()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "tree.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn = confusion_matrix(y_test,y_pred_knn)\n",
    "cm_tree = confusion_matrix(y_test,y_pred_tree)\n",
    "cm_lr = confusion_matrix(y_test,y_pred_lr)\n",
    "cm_rf = confusion_matrix(y_test,y_pred_rf)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "report_tree = classification_report(y_test, y_pred_tree)\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"confusion matrix of k-Nearest Neighbour:\")\n",
    "print(cm_knn)\n",
    "print(\"confusion matrix of Decision Tree:\")\n",
    "print(cm_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"confusion matrix of Logistic Regression:\")\n",
    "print(cm_lr)\n",
    "print(\"confusion matrix of Random Forest:\")\n",
    "print(cm_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_knn,accuracy_tree,accuracy_lr,accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_knn)\n",
    "print(report_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_lr)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy:\n",
    "\n",
    "- KNN achieved an accuracy of approximately 91.92%.\n",
    "- Decision Tree achieved an accuracy of about 88.47%.\n",
    "- Logistic Regression achieved an accuracy of approximately 92.54%.\n",
    "- Random Forest achieved an accuracy of about 92.03%.\n",
    "\n",
    "#### Precision, Recall, and F1-score:\n",
    "- For all algorithms, the classes \"BOMBAY\" have very high precision, recall, and F1-score, close to 1.0. This suggests that these algorithms are very good at correctly identifying instances of the \"BOMBAY\" class.\n",
    "- For the classes \"DERMASON,\" \"HOROZ,\" \"SEKER,\" and \"CALI,\" the precision, recall, and F1-score are relatively high for all algorithms. This indicates good performance in classifying these classes.\n",
    "- The class \"SIRA\" has lower precision, recall, and F1-score values across all algorithms, indicating that it might be more challenging to classify this class accurately.\n",
    "- Overall, the \"weighted avg\" metrics show that Logistic Regression and Random Forest outperform KNN and Decision Tree in terms of overall precision, recall, and F1-score.\n",
    "\n",
    "#### Analysis:\n",
    "\n",
    "- The algorithms KNN, Logistic Regression, and Random Forest all perform reasonably well with accuracy scores above 90%, indicating they are generally good at correctly classifying instances.\n",
    "- Decision Tree has the lowest accuracy among the four algorithms, which suggests it might not be the best choice for this dataset.\n",
    "- Logistic Regression and Random Forest consistently show good performance across multiple evaluation metrics, making them strong candidates for this classification task.\n",
    "- The precision, recall, and F1-scores provide a more detailed view of how well each algorithm performs for different classes. Depending on the specific requirements and goals of your classification task, you may choose one algorithm over the others.\n",
    "\n",
    "In summary, Logistic Regression and Random Forest appear to be the top-performing algorithms based on the provided metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Random Forest classification report, 'Sira' has a precision of 0.88, recall of 0.87, and an F1-score of 0.88. These metrics indicate that the model is moderately accurate in classifying 'Sira' beans as poisonous. Other classes have higher accuracy. Overall model accuracy is 0.92. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"].value_counts().plot(kind='bar', color='blue')\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given the imbalanced nature of the dataset, particularly the 'BOMBAY' class, it's essential to focus on improving the classification performance for the 'SIRA' class without negatively impacting the other classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot the stripplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.drop(columns=['Class']).columns\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(20, 15))\n",
    "for variable, subplot in zip(numerical_cols, ax.flatten()):\n",
    "    g=sns.stripplot(x=df[variable],y=df.Class ,ax=subplot) \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are many outliers for SIRA in the AspectRation, roundness, Compactness, ShapeFactor2-4 in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot the histograms\n",
    "- This helps us better visualise the frequency of values present in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.drop(columns=['Class']).columns\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(15, 15))\n",
    "for variable, subplot in zip(numerical_cols, ax.flatten()):\n",
    "    g=sns.histplot(data=df,x=variable ,ax=subplot) #working with default bin size\n",
    "    g.axvline(x=df[variable].mean(), color='y', label='Mean', linestyle='--', linewidth=2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.drop(columns=['Class']).columns\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(15, 12))\n",
    "\n",
    "for variable, subplot in zip(numerical_cols, ax.flatten()):\n",
    "    g = sns.histplot(data=df, x=variable, ax=subplot, hue='Class', kde=True)\n",
    "    g.set_title(f'Distribution of {variable}')\n",
    "    subplot.axvline(x=df[df['Class'] == 'SIRA'][variable].mean(), color='y', label='SIRA Mean', linestyle='--', linewidth=2)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 2, figsize=(15, 25))\n",
    "\n",
    "for variable, subplot in zip(numerical_cols, ax.flatten()):\n",
    "    sns.boxplot(x=df['Class'], y= df[variable], ax=subplot,palette='pastel')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are many outliers for SIRA in the AspectRation, MajorAxisLength, roundness, Compactness, ShapeFactor2,4 in the dataset\n",
    "- use Isolation Forest algorithm to detect and replace outliers with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "sira_data = df[df['Class'] == 'SIRA']\n",
    "features_to_process = ['AspectRation', 'MajorAxisLength', 'roundness', 'Compactness', 'ShapeFactor2', 'ShapeFactor4']\n",
    "\n",
    "clf = IsolationForest(contamination=0.05, random_state=42)\n",
    "clf.fit(sira_data[features_to_process])\n",
    "outliers = clf.predict(sira_data[features_to_process]) == -1\n",
    "for feature in features_to_process:\n",
    "    median_value = sira_data[feature].median()\n",
    "    sira_data.loc[outliers, feature] = median_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Following this data processing step, the performance of the 'SIRA' class hasn't seen a significant improvement; however, it has maintained its initial level of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f'Cross-Validation Fold {i + 1}: {score}')\n",
    "\n",
    "average_accuracy = cv_scores.mean()\n",
    "print(f'Average Accuracy: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(['SIRA','BOMBAY','DERMASON', 'BARBUNYA', 'HOROZ', 'CALI', 'SEKER',], [1,2,3,4,5,6,0], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "sns.heatmap(df.corr(), yticklabels='auto', annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There a lot of highly correlated attributes in the above correlation matrix, for eg: </br>\n",
    "\n",
    "    *   **Area & Convex Area**:1\n",
    "    *   **Shaped Factor3 & Comapctness**:1\n",
    "    *   **Aspect ration & compactness**: -0.99\n",
    "    *   **Area & Perimeter**: 0.97\n",
    "    *   **Perimeter & ShapeFactor1**: -0.87\n",
    "    *   **Aspect ration & Eccentricity**: 0.92 \n",
    "    \n",
    "    \n",
    "* Some attributes with low level of correlation among them:</br>\n",
    "    *   **Extent & EquivDiameter**: 0.029\n",
    "    *   **Solidity & Eccentricity**: -0.3\n",
    "    *   **Compactnes & Area**: -0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df.quantile(0.25)\n",
    "q3 = df.quantile(0.75)\n",
    "\n",
    "iqr = q3 - q1\n",
    "\n",
    "df1 = df[~((df < (q1 - 1.5 * iqr)) |(df > (q3 + 1.5 * iqr))).any(axis=1)]\n",
    "\n",
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Weighted Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {\n",
    "    'DERMASON': 1.0,\n",
    "    'SIRA': 3.0,\n",
    "    'SEKER': 1.0,\n",
    "    'HOROZ': 1.0,\n",
    "    'CALI': 1.0,\n",
    "    'BARBUNYA': 1.0,\n",
    "    'BOMBAY': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(class_weight=class_weights, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV tuned Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In GridSearchCV tuned Random Forest model, The high recall value of 0.90 for the 'SIRA' class indicates that the model is effective at correctly identifying the majority of samples belonging to the 'SIRA' class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the GridSearchCV tuned Random Forest model generally shows slightly better performance across most classes, with improved precision, recall, and F1-scores in some cases. However, the Class Weighted model may have a slight advantage in maintaining better precision for some classes while trading off with a slight decrease in recall for the 'SIRA' class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
